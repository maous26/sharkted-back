"""  
Collector Footlocker FR - Extraction de produits via JSON-LD.

Footlocker.fr est accessible via cloudscraper et fournit un JSON-LD Product complet.
"""
import json
import re
import time
import random
from typing import Optional

import cloudscraper
from app.utils.http_stealth import create_stealth_scraper, get_stealth_headers, random_delay, get_proxy, should_use_proxy
import requests.exceptions

from app.normalizers.item import DealItem
from app.core.exceptions import (
    BlockedError,
    HTTPError,
    NetworkError,
    TimeoutError,
    DataExtractionError,
    ValidationError,
)
from app.utils.retry import retry_on_network_errors

SOURCE = "footlocker"

_JSONLD_RE = re.compile(
    r'<script[^>]+type=["\']application/ld\+json["\'][^>]*>(.*?)</script>',
    re.IGNORECASE | re.DOTALL,
)


def _extract_sku_from_url(url: str) -> Optional[str]:
    """Extrait le SKU de l'URL (ex: .../314217910604.html -> 314217910604)."""
    match = re.search(r'/(\d{10,})\.html', url)
    return match.group(1) if match else None


def _is_category_page(url: str, html: str = "") -> bool:
    """Détecte si c'est une page de catégorie plutôt qu'une page produit."""
    # Vérifier l'URL d'abord - patterns étendus
    category_patterns = [
        '/category/',
        '/soldes.html',
        '/outlet.html', 
        '/nouveautes.html',
        '/search',
        '/inspiration/',
        '/collection/',
        '/promo',
        '/sale'
    ]
    
    for pattern in category_patterns:
        if pattern in url.lower():
            return True
    
    # Si pas de HTML fourni, on s'arrête à l'URL
    if not html:
        return False
    
    # Vérifier le HTML pour des indicateurs de page catégorie
    category_indicators = [
        r'<meta[^>]*name=["\']robots["\'][^>]*content=["\'][^"\']*(?:noindex|nofollow)[^"\']*',
        r'class=["\'][^"\']*(?:product-listing|category|search-results)[^"\']*',
        r'<title[^>]*>\s*Foot Locker France\s*</title>',
        r'aria-label=["\']Principaux["\']',  # Navigation principale
        r'HeaderNavigation',  # Navigation header spécifique à footlocker
        r'<link[^>]*rel=["\']canonical["\'][^>]*href=["\'][^"\']*(?:/category/|/soldes\.html)',
        r'data-bi=["\'][^""]*location[""]*:[""]*promos',  # Carrousel promos
        r'Carrousel de promotions',  # Texte spécifique aux pages catégorie
        r'aria-label=["\']Showing banner \d+ of \d+',  # Banners de promotion
        r'class=["\'][^"\']*(?:promo_banner_slide|NavigationMenu--list)[^"\']*',
    ]
    
    for pattern in category_indicators:
        if re.search(pattern, html, re.IGNORECASE):
            return True
    
    # Vérifier le JSON-LD - si seulement WebSite sans Product
    has_website_jsonld = False
    has_product_jsonld = False
    
    for match in _JSONLD_RE.finditer(html):
        try:
            jsonld = json.loads(match.group(1).strip())
            if isinstance(jsonld, dict):
                if jsonld.get("@type") == "WebSite":
                    has_website_jsonld = True
                elif jsonld.get("@type") == "Product":
                    has_product_jsonld = True
        except (json.JSONDecodeError, KeyError):
            continue
    
    # Page de catégorie si WebSite présent mais pas de Product
    if has_website_jsonld and not has_product_jsonld:
        return True
    
    return False


def _detect_blocking_protection(html: str) -> tuple[bool, str]:
    """Détecte la présence de protections anti-bot."""
    # Kasada protection - patterns améliorés et plus spécifiques
    kasada_patterns = [
        r'/[a-f0-9-]{36}/[a-f0-9-]{36}/p\.js',  # Script Kasada spécifique
        r'kpsdk-load',
        r'window\.KPSDK',
        r'document\.addEventListener\(["\']kpsdk-load',
        r'KPSDK\.configure',
        r'window\.KPSDK\.configure',  # Pattern plus spécifique
    ]
    
    for pattern in kasada_patterns:
        if re.search(pattern, html):
            return True, "Kasada"
    
    # Queue-it (file d'attente) - patterns améliorés
    queue_patterns = [
        r'queue-it\.net',
        r'queueclient',
        r'queueconfigloader',
        r'data-queueit-c=',
        r'static\.queue-it\.net/script/',
    ]
    
    for pattern in queue_patterns:
        if re.search(pattern, html, re.IGNORECASE):
            return True, "Queue-it"
    
    # Cloudflare protection
    cloudflare_patterns = [
        r'cf-ray',
        r'cloudflare',
        r'cf-browser-verification',
        r'__cf_bm',
        r'cf-challenge',
    ]
    
    for pattern in cloudflare_patterns:
        if re.search(pattern, html, re.IGNORECASE):
            return True, "Cloudflare"
    
    # Autres protections courantes
    other_patterns = [
        r'blocked',
        r'access[\s\.]denied',
        r'bot[\s\.]detected',
        r'security[\s\.]check',
        r'captcha',
        r'please[\s\.]wait',
    ]
    
    for pattern in other_patterns:
        if re.search(pattern, html, re.IGNORECASE):
            return True, "Unknown"
    
    return False, ""


def _extract_product_data(html: str, url: str) -> dict:
    """
    Extrait les données produit depuis le JSON-LD.
    Footlocker fournit un JSON-LD Product complet.
    """
    data = {
        "name": None,
        "price": None,
        "original_price": None,
        "discount_percent": None,
        "currency": "EUR",
        "image": None,
        "sku": _extract_sku_from_url(url),
        "brand": None,
    }

    # Chercher le JSON-LD Product
    for match in _JSONLD_RE.finditer(html):
        try:
            jsonld = json.loads(match.group(1).strip())
            if isinstance(jsonld, dict) and jsonld.get("@type") == "Product":
                data["name"] = jsonld.get("name")
                data["brand"] = jsonld.get("brand")
                data["sku"] = jsonld.get("sku") or data["sku"]

                # Image peut être string ou array
                image = jsonld.get("image")
                if isinstance(image, list):
                    data["image"] = image[0] if image else None
                else:
                    data["image"] = image

                # Prix dans offers
                offers = jsonld.get("offers", {})
                if isinstance(offers, dict):
                    price = offers.get("price")
                    if price:
                        try:
                            data["price"] = float(price)
                        except (ValueError, TypeError):
                            pass
                    data["currency"] = offers.get("priceCurrency", "EUR")
                elif isinstance(offers, list) and offers:
                    price = offers[0].get("price")
                    if price:
                        try:
                            data["price"] = float(price)
                        except (ValueError, TypeError):
                            pass
                    data["currency"] = offers[0].get("priceCurrency", "EUR")

                break
        except (json.JSONDecodeError, KeyError):
            continue
    
    # Prix original (prix barré dans le HTML)
    was_price_patterns = [
        r'class="[^"]*(?:was|strike|crossed|old|original)[^"]*"[^>]*>([^<]*[0-9]+[,.]?[0-9]*)',
        r'data-price-was="([^"]+)"',
        r'<span[^>]*class="[^"]*price[^"]*was[^"]*"[^>]*>([^<]+)</span>'
    ]
    
    for pattern in was_price_patterns:
        was_price = re.search(pattern, html, re.IGNORECASE)
        if was_price:
            try:
                price_str = re.sub(r'[^\d.,]', '', was_price.group(1)).replace(",", ".")
                if price_str:
                    data["original_price"] = float(price_str)
                    break
            except ValueError:
                continue
    
    # Calcul discount_percent
    if data["price"] and data["original_price"] and data["original_price"] > data["price"]:
        data["discount_percent"] = round(
            (1 - data["price"] / data["original_price"]) * 100, 1
        )

    # Fallback: meta tags si JSON-LD incomplet
    if not data["name"]:
        meta_patterns = [
            r'<meta property="og:title"[^>]*content="([^"]+)"',
            r'<meta name="title"[^>]*content="([^"]+)"',
            r'<title[^>]*>([^<]+)</title>'
        ]
        
        for pattern in meta_patterns:
            match = re.search(pattern, html)
            if match:
                title = match.group(1).strip()
                if title and title != "Foot Locker France" and not re.search(r'\b(category|soldes|outlet)\b', title.lower()):
                    data["name"] = title
                    break

    if not data["image"]:
        og_image = re.search(r'<meta property="og:image"[^>]*content="([^"]+)"', html)
        if og_image:
            data["image"] = og_image.group(1)

    return data


def _create_enhanced_scraper() -> tuple[cloudscraper.CloudScraper, dict]:
    """Crée un scraper avec paramètres anti-détection renforcés."""
    scraper = cloudscraper.create_scraper(
        browser={
            'browser': 'chrome',
            'platform': 'windows',
            'mobile': False
        },
        delay=random.uniform(1, 3)
    )
    
    # Headers ultra-réalistes pour éviter Kasada
    headers = {
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Language': 'fr-FR,fr;q=0.9,en-US;q=0.8,en;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0',
        'Sec-CH-UA': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
        'Sec-CH-UA-Mobile': '?0',
        'Sec-CH-UA-Platform': '"Windows"',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    return scraper, headers


@retry_on_network_errors(retries=3, source=SOURCE)
def fetch_footlocker_product(url: str) -> DealItem:
    """
    Récupère et parse un produit Footlocker FR.

    Raises:
        BlockedError: Si bloqué
        TimeoutError: Si timeout réseau
        NetworkError: Si erreur réseau
        HTTPError: Si erreur HTTP autre
        DataExtractionError: Si données non trouvées
        ValidationError: Si données invalides
    """
    # Vérification préliminaire de l'URL - check immédiat des patterns de catégorie
    if _is_category_page(url):
        raise DataExtractionError(
            "URL de catégorie détectée - une URL de produit spécifique est requise (ex: /product/nom-produit/123456789.html)",
            source=SOURCE,
            url=url,
        )
    
    # Délai aléatoire pour éviter la détection
    time.sleep(random.uniform(2, 5))
    
    scraper, headers = _create_enhanced_scraper()
    
    max_retries = 3
    base_delay = 2
    
    for attempt in range(max_retries):
        try:
            # Utiliser systématiquement des proxies pour Footlocker
            proxies = get_proxy() if should_use_proxy("footlocker") else None
            
            # Timeout plus long pour laisser le temps aux protections
            resp = scraper.get(
                url, 
                headers=headers, 
                proxies=proxies, 
                timeout=45,
                allow_redirects=True
            )
            break
            
        except requests.exceptions.Timeout as e:
            if attempt == max_retries - 1:
                raise TimeoutError(
                    "Timeout après 45s",
                    source=SOURCE,
                    url=url,
                ) from e
            time.sleep(base_delay * (2 ** attempt))
            continue
            
        except requests.exceptions.ConnectionError as e:
            if attempt == max_retries - 1:
                raise NetworkError(
                    f"Erreur de connexion: {e}",
                    source=SOURCE,
                    url=url,
                ) from e
            time.sleep(base_delay * (2 ** attempt))
            continue
            
        except requests.exceptions.RequestException as e:
            if attempt == max_retries - 1:
                raise NetworkError(
                    f"Erreur réseau: {e}",
                    source=SOURCE,
                    url=url,
                ) from e
            time.sleep(base_delay * (2 ** attempt))
            continue

    # Détecter les protections anti-bot en premier
    is_blocked, protection_type = _detect_blocking_protection(resp.text)
    if is_blocked:
        # Si c'est une page de catégorie avec protection, message spécifique
        if _is_category_page(url, resp.text):
            raise DataExtractionError(
                f"URL de catégorie détectée avec protection {protection_type} - utilisez une URL de produit spécifique",
                source=SOURCE,
                url=url,
            )
        else:
            raise BlockedError(
                f"Protection anti-bot {protection_type} détectée (HTTP {resp.status_code}). Footlocker utilise des protections avancées qui nécessitent des outils spécialisés.",
                source=SOURCE,
                url=url,
                status_code=resp.status_code,
            )

    # Vérifier si c'est une page de catégorie avant de traiter les codes HTTP
    if _is_category_page(url, resp.text):
        raise DataExtractionError(
            "Cette URL pointe vers une page de catégorie, pas vers un produit spécifique. Footlocker nécessite l'URL d'un produit individuel (ex: /product/nom-produit/123456789.html).",
            source=SOURCE,
            url=url,
        )

    # Vérifier le status HTTP
    if resp.status_code == 403:
        raise BlockedError(
            "Bloqué par protection anti-bot (403)",
            source=SOURCE,
            url=url,
            status_code=403,
        )

    if resp.status_code == 404:
        raise DataExtractionError(
            "Produit non trouvé (404)",
            source=SOURCE,
            url=url,
        )

    if resp.status_code == 400:
        # Pour HTTP 400, c'est probablement un blocage après vérifications précédentes
        raise BlockedError(
            "Erreur HTTP 400 - Requête invalide, possiblement bloquée par protection anti-bot Kasada. Un contournement spécialisé est nécessaire.",
            source=SOURCE,
            url=url,
            status_code=400,
        )

    if resp.status_code >= 400:
        raise HTTPError(
            f"Erreur HTTP {resp.status_code}",
            status_code=resp.status_code,
            source=SOURCE,
            url=url,
        )

    # Extraire les données
    data = _extract_product_data(resp.text, url)

    # Validation
    if not data["name"]:
        raise DataExtractionError(
            "Nom du produit non trouvé - vérifiez que l'URL pointe vers un produit valide",
            source=SOURCE,
            url=url,
        )

    if not data["price"] or data["price"] <= 0:
        raise ValidationError(
            f"Prix invalide: {data['price']}",
            field="price",
            source=SOURCE,
            url=url,
        )

    # Construire l'external_id
    external_id = data["sku"] or url.split("/")[-1].replace(".html", "")

    return DealItem(
        source=SOURCE,
        external_id=external_id,
        title=data["name"],
        price=data["price"],
        original_price=data.get("original_price"),
        discount_percent=data.get("discount_percent"),
        currency=data["currency"],
        url=url,
        image_url=data["image"],
        seller_name=data["brand"],
        brand=data["brand"],
        raw=data,
    )